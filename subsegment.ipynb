{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92a21d3",
   "metadata": {},
   "source": [
    "# Subsegmentation of ALIC tracts\n",
    "\n",
    "This notebook is used for rapid prototyping of the ALIC segmentation pipeline. Once complete and relatively stable, it will be converted to a python script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ab2127",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f2b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('wma_pyTools')\n",
    "\n",
    "# import wmaPyTools.roiTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-fabric",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import itertools\n",
    "import numpy as np\n",
    "from warnings import warn\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from scipy import ndimage\n",
    "#import random\n",
    "\n",
    "#make sure that wma_pyTools is right in the working directory, or that\n",
    "#the package can otherwise be imported effectively\n",
    "#sys.path.append('wma_pyTools')\n",
    "startDir=Path(os.getcwd())\n",
    "import pandas as pd\n",
    "import wmaPyTools.roiTools\n",
    "import wmaPyTools.analysisTools\n",
    "import wmaPyTools.segmentationTools\n",
    "import wmaPyTools.streamlineTools\n",
    "import wmaPyTools.visTools\n",
    "\n",
    "#dipy\n",
    "from dipy.tracking.utils import reduce_labels\n",
    "from dipy.tracking import utils\n",
    "import dipy.io.streamline\n",
    "from dipy.tracking.utils import density_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract and organize inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0780a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coregister B0 image into acpc space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a313813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define expected inputs and check for them\n",
    "data_dir = startDir /'indata'\n",
    "\n",
    "parcellationPath = data_dir / 'aparc+aseg.nii.gz'\n",
    "refT1Path = data_dir / 'T1w_acpc_dc_restore.nii.gz'\n",
    "diffPath = data_dir / 'eddy_wrapped_avg_image_space-acpc.nii.gz'\n",
    "diff_b0acpc_path = data_dir / 'eddy_wrapped_B0_image_space-acpc.nii.gz'\n",
    "diff_unreg_path = data_dir /'eddy_wrapped_avg_image.nii.gz'\n",
    "bvalsPath = data_dir / 'bvals'\n",
    "bvalsPath_b9 = data_dir / 'bvals_b9'\n",
    "bvecsPath = data_dir / 'bvecs'\n",
    "ParcellationFsPath = data_dir / 'mri/aparc+aseg.mgz'\n",
    "rACC_mod_aparc_aseg = data_dir / 'rACC_mod_aparc_aseg.nii.gz'\n",
    "rACC_split_labels = {11026: data_dir / 'lh_rostralanteriorcingulate_ROI_acpc_1.nii.gz',\n",
    "                     21026: data_dir / 'lh_rostralanteriorcingulate_ROI_acpc_2.nii.gz',\n",
    "                    12026: data_dir / 'rh_rostralanteriorcingulate_ROI_acpc_1.nii.gz',\n",
    "                     22026: data_dir / 'rh_rostralanteriorcingulate_ROI_acpc_2.nii.gz'}\n",
    "\n",
    "\n",
    "# Freesurfer lookup table, e.g. https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/AnatomicalROI/FreeSurferColorLUT\n",
    "lutPath = data_dir / 'FreesurferLookup.csv'\n",
    "\n",
    "#tckPath=Path('/home/naxos2-raid25/sreta001/DBS_for_sreta001/DBS-OCD/OCD004/Code/app-track_aLIC_harelpreproc/output/track.tck')\n",
    "saveFigDir = startDir / 'output'\n",
    "\n",
    "to_check = [ parcellationPath, refT1Path, lutPath, diff_b0acpc_path, \n",
    "            diff_unreg_path, ParcellationFsPath, bvalsPath, bvalsPath_b9, bvecsPath]\n",
    "for i in to_check:\n",
    "    print(i)\n",
    "    if not i.is_file():\n",
    "        warn('%s doesn''t exist!' % str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8096f803",
   "metadata": {},
   "source": [
    "## run app-track_aLIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb51da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save python variables for use by bash\n",
    "os.environ['bvalsPath'] = str(bvalsPath)\n",
    "os.environ['diffPath'] = str(diffPath)\n",
    "os.environ['bvalsPath_b9'] = str(bvalsPath_b9)\n",
    "os.environ['diff_b0acpc_path'] = str(diff_b0acpc_path)\n",
    "os.environ['diff_unreg_path'] = str(diff_unreg_path)\n",
    "os.environ['startDir'] = str(startDir)\n",
    "#os.environ[''] = str()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c744acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "# Edit bvals file so that B0s have b-value 9 instead of 10\n",
    "\n",
    "sed -e 's/^10/9/g' -e 's/ 10 / 9 /g' -e 's/10$/9/g' ${bvalsPath} > ${bvalsPath_b9}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84da388e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "# copy affine from eddy_wrapped_B0_image_space-acpc.nii.gz to eddy_wrapped_avg_image_space-acpc.nii.gz\n",
    "\n",
    "cp ${diff_unreg_path} ${diffPath}\n",
    "fslcpgeom ${diff_b0acpc_path} ${diffPath} -d # -d option is needed to preserve the 4-d volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f9103d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "# link indata to app-track_aLIC/indata\n",
    "ln -s \"../indata\" \"${startDir}/app-track_aLIC/indata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4b5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script  bash\n",
    "# invert acpc to mni xfm\n",
    "convert_xfm -omat \"indata/MNI2acpcLinear.mat\" -inverse \"indata/acpc2MNILinear.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72737d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "# fails if ran on jupyter notebook, run in terminal instead\n",
    "# run \"main\" app-track_aLIC script\n",
    "export APPTAINER_BIND=\"/home,${APPTAINER_BIND}\"\n",
    "\n",
    "cd \"${startDir}/app-track_aLIC\" #navigate to startDir, then run ./main\n",
    "./main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb5c37f",
   "metadata": {},
   "source": [
    "## Modify aparc+aseg with divided rACC ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4936e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load aparc+aseg in acpc\n",
    "aparc_aseg = nib.load(parcellationPath)\n",
    "aparc_aseg_voxel_grid = aparc_aseg.get_fdata()\n",
    "\n",
    "#load rACC masks and voxel grid\n",
    "for key, value in rACC_split_labels.items():\n",
    "    rACC_ROI = nib.load(value)\n",
    "    rACC_ROI_voxel_grid = rACC_ROI.get_fdata() #values either 0 and 1 because it's a mask\n",
    "    aparc_aseg_voxel_grid[rACC_ROI_voxel_grid>0.5] = key #selecting aparc_aseg voxels within rACC mask and output corresponding key\n",
    "\n",
    "aparc_aseg_nifti = nib.Nifti1Image(aparc_aseg_voxel_grid,aparc_aseg.affine) #convert to nifti image\n",
    "nib.save(aparc_aseg_nifti,filename=rACC_mod_aparc_aseg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5e8b3d",
   "metadata": {},
   "source": [
    "## Subsegment Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetLabels={'left':[1002,11026,21026,1012,1020,1028,1003,1014,1019,1027],\n",
    "              'right':[2002,12026,22026,2012,2020,2028,2003,2014,2019,2027]}\n",
    "spineLabels = {'left': [28, 16, 10], \n",
    "               'right': [16, 60, 49]}\n",
    "\n",
    "#paths to input data\n",
    "\n",
    "track_files = {\n",
    "    'left': [startDir / 'app-track_aLIC' / 'output' / 'combined_aLIC_left.tck',],\n",
    "    'right': [startDir / 'app-track_aLIC' / 'output' / 'combined_aLIC_right.tck',]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b7e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check inputs\n",
    "to_check = [ parcellationPath, refT1Path, lutPath]\n",
    "for side in ['left', 'right']:\n",
    "    for tck in track_files[side]:\n",
    "        to_check.append(tck)\n",
    "        \n",
    "for i in to_check:\n",
    "    print(i)\n",
    "    assert(i.is_file())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6a531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to generate tck for target\n",
    "\n",
    "def get_streams_matching_target(streams, atlas, target):\n",
    "    target_mask=wmaPyTools.roiTools.multiROIrequestToMask(atlas,target)\n",
    "    # return boolean mask for stream selection\n",
    "    return wmaPyTools.segmentationTools.segmentTractMultiROI(streams, \n",
    "                    [target_mask,], \n",
    "                    [True,], \n",
    "                    ['either_end',]) \n",
    "    \n",
    "def save_density_map(streams, ref_img, out_file):\n",
    "    density=utils.density_map(streams, ref_img.affine, ref_img.shape)\n",
    "    densityNifti = nib.nifti1.Nifti1Image(density, ref_img.affine, ref_img.header)\n",
    "    nib.save(densityNifti, out_file)\n",
    "    \n",
    "def save_streams_matching_target(streams, atlas, lookupTable, target, out_file):\n",
    "    strTarget = lookupTable.loc[target, 'LabelName:']\n",
    "    print('target label is: %s (%s)' % (target, strTarget))\n",
    "    #out_file = Path(save_dir) / ('track_%04d_%s' % (target,strTarget)) #no file extension yet, add it later\n",
    "    print(out_file)\n",
    "    # get boolean vector of matching streams\n",
    "    targetBool = get_streams_matching_target(streams, atlas, target)\n",
    "    streams = streams[targetBool]\n",
    "    \n",
    "    #dipy quickbundles\n",
    "    streams = streams[bundle(streams)]\n",
    "    \n",
    "    #save *.tck tractogram\n",
    "    wmaPyTools.streamlineTools.stubbornSaveTractogram(streams,\n",
    "        savePath=str(out_file.with_suffix('.tck')))\n",
    "    # save nifti density map\n",
    "    save_density_map(streams, atlas, out_file.with_suffix('.nii.gz'))\n",
    "    return targetBool\n",
    "    \n",
    "#targetBool = save_streams_matching_target(streams,inflatedAtlas, lookupTable, iTarget, saveFigDir)\n",
    "#wmaPyTools.streamlineTools.stubbornSaveTractogram(streams[targetBool], \n",
    "#    savePath=str(saveFigDir / '1002_test.tck' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the initial culling, to remove extraneous streamlines \n",
    "#first requires doing a DIPY quickbundling\n",
    "def bundle(streams):\n",
    "    print(\"DIPY quickbundle\")\n",
    "    clusters=wmaPyTools.streamlineTools.quickbundlesClusters(streams, thresholds = [30,20,10], nb_pts=100)\n",
    "\n",
    "    #use those clusters to identify the streamlines to be culled\n",
    "    print(\"identify streamlines to remove\")\n",
    "    survivingStreamsIndices, culledStreamIndicies=wmaPyTools.streamlineTools.cullViaClusters(clusters,streams,3)\n",
    "    #convert survivingStreamsIndicies into a bool vec\n",
    "    survivingStreamsBoolVec=np.zeros(len(streams),dtype=bool)\n",
    "    survivingStreamsBoolVec[survivingStreamsIndices]=True\n",
    "    \n",
    "    print('%d of %d streams survived' % (len(survivingStreamsIndices), len(survivingStreamsBoolVec)))\n",
    "    \n",
    "    return survivingStreamsBoolVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274bfe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load atlas-based segmentation - modified rACC mask (Dan calls it a parcellation)\n",
    "parcellaton=nib.load(rACC_mod_aparc_aseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9d10b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load T1 anatomical image\n",
    "refT1=nib.load(refT1Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff76a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Freesurfer labels\n",
    "lookupTable=pd.read_csv(lutPath,index_col='#No.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dfbf2e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#perform inflate & deIsland of input parcellation\n",
    "inflated_atlas_file = saveFigDir / Path(Path(rACC_mod_aparc_aseg.stem).stem + '_inflated').with_suffix('.nii.gz')\n",
    "print(inflated_atlas_file)\n",
    "inflatedAtlas,deIslandReport,inflationReport= wmaPyTools.roiTools.preProcParc(parcellaton,deIslandBool=True,inflateIter=2,retainOrigBorders=False,maintainIslandsLabels=None,erodeLabels=[2,41])    \n",
    "nib.save(inflatedAtlas,filename=inflated_atlas_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd264b02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Main cell, do all the hard work\n",
    "\n",
    "for iSide in ['left', 'right']:\n",
    "    for track_file in track_files[iSide]:        \n",
    "        # load & orient streamlines\n",
    "        \n",
    "        tck_oriented_file = saveFigDir / Path(track_file.stem + '_oriented').with_suffix('.tck')\n",
    "        if tck_oriented_file.exists():\n",
    "            print('oriented tck already exists. loading %s' % tck_oriented_file)\n",
    "            tckIn=nib.streamlines.load(tck_oriented_file)\n",
    "            streams = tckIn.streamlines\n",
    "        else:\n",
    "            print('Load tck %s' % track_file)\n",
    "            tckIn=nib.streamlines.load(track_file)\n",
    "            print(\"orienting streamlines\")\n",
    "            streams=wmaPyTools.streamlineTools.orientAllStreamlines(tckIn.streamlines)\n",
    "            # do quickbundles (never mind, takes too long)\n",
    "            #streams = streams[bundle(streams)]\n",
    "            # save oriented + bundled streams\n",
    "            print('saving oriented tck %s' % tck_oriented_file)\n",
    "            wmaPyTools.streamlineTools.stubbornSaveTractogram(streams,savePath=str(tck_oriented_file))\n",
    "        \n",
    "        parent_density_file = saveFigDir / Path(track_file.stem).with_suffix('.nii.gz')\n",
    "        print('saving density map %s' % parent_density_file)\n",
    "        save_density_map(streams, inflatedAtlas, parent_density_file)\n",
    "        \n",
    "        for iTarget in targetLabels[iSide]:\n",
    "            targetStr = lookupTable.loc[iTarget, 'LabelName:']\n",
    "            out_file = saveFigDir / ('%s_%04d_%s' % (track_file.stem, iTarget, targetStr))\n",
    "            print('Starting processing for %s' % out_file.stem)\n",
    "            \n",
    "            # subsegment the streams and save the resulting density map and tck tractogram\n",
    "            targetBool = save_streams_matching_target(streams, inflatedAtlas, lookupTable, iTarget, out_file)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c505057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroid for each pathway\n",
    "APaxis = 1\n",
    "\n",
    "for iSide in ['left', 'right']: #iterate over each hemisphere\n",
    "    for track_file in track_files[iSide]: \n",
    "        for iTarget in targetLabels[iSide]: #iterate over each pathway\n",
    "            targetStr = lookupTable.loc[iTarget, 'LabelName:'] #label corresponding to each pathway\n",
    "            in_file = saveFigDir / ('%s_%04d_%s' % (track_file.stem, iTarget, targetStr)) #generate input file\n",
    "            in_nifti = nib.load(in_file.with_suffix('.nii.gz')) #load nifti of a pathway\n",
    "            in_img = in_nifti.get_fdata() #convert nifti into a voxel array\n",
    "            num_slices = np.shape(in_img)[APaxis]\n",
    "            out_file = saveFigDir / ('%s_%04d_%s_centerofmass' % (track_file.stem, iTarget, targetStr)) #output center of mass image\n",
    "            centerofmass = np.zeros([num_slices,3]) #numerical array corresponding to x,y,z coordinates of centroid\n",
    "            for iSlice in range(num_slices): #interating over total number of coronal slides of input image\n",
    "                img_slice = in_img[:,iSlice,:] #an individual slice\n",
    "                tmp = ndimage.center_of_mass(img_slice, labels=None, index=None) #step that calculates COM for each slice\n",
    "                centerofmass[iSlice,:] = [tmp[0],iSlice,tmp[1]] #adding iSlice at APaxis=1\n",
    "            centerofmass = centerofmass[~np.any(np.isnan(centerofmass),axis=1)]\n",
    "            nib.affines.apply_affine(in_nifti.affine, centerofmass, inplace=True)\n",
    "            np.savetxt(out_file.with_suffix('.csv'), centerofmass, delimiter=\",\") #save output file as a .csv for all slices\n",
    "            \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a68920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate (within ALIC) centroid for each pathway using ALIC mask\n",
    "#lh_ALIC_mask = fullCutIC_ROI11_left.nii.gz\n",
    "#rh_ALIC_mask = fullCutIC_ROI11_right.nii.gz\n",
    "\n",
    "ALIC_mask_dir = {'left': data_dir / 'fullCutIC_ROI11_left.nii.gz',\n",
    "                'right': data_dir/ 'fullCutIC_ROI11_right.nii.gz'}\n",
    "\n",
    "APaxis = 1\n",
    "\n",
    "for iSide in ['left', 'right']: #iterate over each hemisphere\n",
    "    ALIC_mask = nib.load(ALIC_mask_dir[iSide])#loading ALIC mask\n",
    "    for track_file in track_files[iSide]: \n",
    "        for iTarget in targetLabels[iSide]: #iterate over each pathway\n",
    "            targetStr = lookupTable.loc[iTarget, 'LabelName:'] #label corresponding to each pathway\n",
    "            in_file = saveFigDir / ('%s_%04d_%s' % (track_file.stem, iTarget, targetStr)) #generate input file\n",
    "            in_nifti = nib.load(in_file.with_suffix('.nii.gz')) #load nifti of a pathway\n",
    "            in_img = in_nifti.get_fdata() #convert nifti into a voxel array\n",
    "            resample_ALIC_mask = dipy.align.resample(ALIC_mask,in_nifti) #resample ALIC mask nifti into heatmap nifti dimensions\n",
    "            in_img = in_img*resample_ALIC_mask.get_fdata() #multiply ALIC density map voxel array by resampled ALIC mask array\n",
    "            num_slices = np.shape(in_img)[APaxis]\n",
    "            out_file = saveFigDir / ('%s_%04d_%s_centerofmass_withinALIC' % (track_file.stem, iTarget, targetStr)) #output center of mass image\n",
    "            centerofmass = np.zeros([num_slices,3]) #numerical array corresponding to x,y,z coordinates of centroid\n",
    "            for iSlice in range(num_slices): #interating over total number of coronal slides of input image\n",
    "                img_slice = in_img[:,iSlice,:] #an individual slice\n",
    "                tmp = ndimage.center_of_mass(img_slice, labels=None, index=None) #step that calculates COM for each slice\n",
    "                centerofmass[iSlice,:] = [tmp[0],iSlice,tmp[1]] #adding iSlice at APaxis=1\n",
    "            centerofmass = centerofmass[~np.any(np.isnan(centerofmass),axis=1)]\n",
    "            nib.affines.apply_affine(in_nifti.affine, centerofmass, inplace=True)\n",
    "            np.savetxt(out_file.with_suffix('.csv'), centerofmass, delimiter=\",\") #save output file as a .csv for all slices\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2463a2",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b47653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate combined niftis which are the sum of all sides\n",
    "for iSide in ['left', 'right']:\n",
    "    for iTarget in targetLabels[iSide]:\n",
    "        combined_img = np.zeros(refT1.shape)\n",
    "        for track_file in track_files[iSide]:  # iterate over inferior and superior\n",
    "            targetStr = lookupTable.loc[iTarget, 'LabelName:']\n",
    "            in_file = saveFigDir / ('%s_%04d_%s' % (track_file.stem, iTarget, targetStr))\n",
    "            print(in_file)\n",
    "            combined_img += nib.load(in_file.with_suffix('.nii.gz')).get_fdata()\n",
    "        combined_file  = saveFigDir / ('combined_aLIC_%04d_%s' % ( iTarget, targetStr))\n",
    "        combinedNifti = nib.nifti1.Nifti1Image(combined_img, refT1.affine, refT1.header)\n",
    "        print(combined_file)\n",
    "        nib.save(combinedNifti, combined_file.with_suffix('.nii.gz'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943d5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tractogram\n",
    "# SKIPPED because we're iterating over multiple tractograms\n",
    "tckIn=nib.streamlines.load(tckPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e7ae7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# orient all the steamlines, potentially not necessary given redundancy with \n",
    "# subsequent steps\n",
    "# SKIPPED because we're using either_end selection\n",
    "\n",
    "print(\"orienting streamlines\")\n",
    "orientedStreams=wmaPyTools.streamlineTools.orientAllStreamlines(tckIn.streamlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da290219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save oriented streams\n",
    "# SKIPPED\n",
    "print(\"save oriented tck\")\n",
    "subTckSavePath=os.path.join(saveFigDir,'track_oriented.tck')\n",
    "wmaPyTools.streamlineTools.stubbornSaveTractogram(orientedStreams,savePath=subTckSavePath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f4b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save lite streamlines\n",
    "#SKIPPED\n",
    "n_streams_to_keep = int(5E5)\n",
    "select_bool = np.random.choice(range(len(orientedStreams)), n_streams_to_keep, replace=False)\n",
    "lite_streams = orientedStreams[select_bool]\n",
    "wmaPyTools.streamlineTools.stubbornSaveTractogram(lite_streams,\n",
    "    savePath=str(Path(saveFigDir) / 'track_lite.tck'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10654e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select streamlines to work on\n",
    "\n",
    "streams = lite_streams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ef4764",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dipy.tracking.utils import density_map\n",
    "from wmaPyTools.visTools import multiTileDensity\n",
    "\n",
    "multiTileDensity(streams,refT1,saveFigDir,'density',densityThreshold=0,noEmpties=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b8f2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "M, grouping = utils.connectivity_matrix(streams, inflatedAtlas.affine, inflatedAtlas.get_fdata().astype(np.int),\n",
    "                                        return_mapping=True,\n",
    "                                        mapping_as_streamlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3571e6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = targetLabels['left'] + targetLabels['right']\n",
    "targets.sort()\n",
    "for iTarget in targets:\n",
    "    print(iTarget)\n",
    "    print(lookupTable.loc[iTarget, 'LabelName:'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d698d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(bvalsPath, 'r') as f:\n",
    "    x = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f233805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = split(x, ' ')\n",
    "y = x[0].split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d8005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e81341",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27fab6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
